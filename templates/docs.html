{% extends "base.html" %}
{% set active_page = "docs" %}

{% block title %}Documentation - upg-strings{% endblock %}
{% block description %}Installation and usage documentation for upg-strings.{% endblock %}
{% block og_tags %}
    <meta property="og:title" content="Documentation - upg-strings">
    <meta property="og:description" content="Installation and usage documentation for upg-strings.">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://compute.upg.gr/docs.html">
{% endblock %}

{% block content %}
    <main class="container">
        <section class="section">
            <h1>Documentation</h1>
        </section>

        <section class="section">
            <h2>For Scientists</h2>
            <p>Use the application to quickly surface rare Calabi-Yau candidates while keeping a reproducible record.</p>
            <ul>
                <li>Run searches in the web UI or CLI to rank candidates by predicted likelihood</li>
                <li>Verify top-k hits and track precision/recall for experimental comparison</li>
                <li>Export CSV/JSON artifacts for downstream analysis and sharing</li>
                <li>Record random seeds and dataset metadata for reproducibility</li>
            </ul>
        </section>

        <section class="section">
            <h2>Installation Prerequisites</h2>
            <ul>
                <li>Python 3.9 or higher</li>
                <li>pip package manager</li>
                <li>4GB RAM minimum (8GB recommended)</li>
                <li>2GB free disk space for datasets and outputs</li>
            </ul>

            <h3>Quick Install</h3>
            <div class="code-block">
                <code>git clone https://github.com/upggr/compute.upg.gr.git<br>
cd compute.upg.gr<br>
pip install -r requirements.txt</code>
            </div>
        </section>

        <section class="section">
            <h2>How to Run</h2>

            <h3>Basic Run</h3>
            <div class="code-block">
                <code>python cy_search_real.py</code>
            </div>

            <h3>Web App</h3>
            <div class="code-block">
                <code>python app.py</code>
            </div>

            <h3>Expected Runtime</h3>
            <p>5-15 minutes on standard hardware, depending on dataset size and CPU performance.</p>

            <h3>Output Location</h3>
            <p>All artifacts are saved to <code>./output/</code> directory:</p>
            <ul>
                <li><code>output/results_topk.csv</code> - Top-k ranked results</li>
                <li><code>output/metrics.json</code> - Performance metrics</li>
                <li><code>output/repro.md</code> - Reproducibility report</li>
            </ul>

            <h3>Run Exports</h3>
            <p>The Run page provides download buttons for JSON/CSV plus tool-friendly exports for CYTools, cymetric, Sage, and Mathematica.</p>

            <h3>Import / Export (API)</h3>
            <p>Use the REST API to import datasets or export results programmatically.</p>
            <div class="code-block">
                <code># Import: score custom candidates and save a run<br>
curl -X POST https://compute.upg.gr/api/score-custom -H "Content-Type: application/json" \\<br>
  -d '{"dataset_id":"kreuzer-skarke","rows":[[12,45,66,3.75,924]],"top_k":20,"seed":42,"verify":true,"save":true}'<br>
<br>
# Export: fetch results in tool-friendly formats<br>
curl -o results.json "https://compute.upg.gr/api/export/RUN_ID?format=json"<br>
curl -o results.csv "https://compute.upg.gr/api/export/RUN_ID?format=csv"<br>
curl -o cytools.json "https://compute.upg.gr/api/export/RUN_ID?format=cytools"<br>
curl -o cymetric.json "https://compute.upg.gr/api/export/RUN_ID?format=cymetric"<br>
curl -o candidates.sage "https://compute.upg.gr/api/export/RUN_ID?format=sage"<br>
curl -o candidates.wl "https://compute.upg.gr/api/export/RUN_ID?format=mathematica"</code>
            </div>

            <h3>Per-Tool Schemas</h3>
            <p>Exports share the same candidate objects, packaged per tool. Each candidate includes the fields returned by the dataset formatter.</p>
            <div class="code-block">
                <code># Kreuzer-Skarke candidate fields<br>
rank, h11, h21, euler_char, score, verified_target<br>
<br>
# CY5-Folds candidate fields<br>
rank, h11, h21, h31, euler_char, score, verified_target<br>
<br>
# Heterotic candidate fields<br>
rank, h11, h21, euler_char, hodge_balance, n_generations, score, verified_target<br>
<br>
# CYTools / cymetric JSON wrapper<br>
{ "schema": "cytools-candidates-v1", "run_metadata": {...}, "candidates": [ ... ] }<br>
{ "schema": "cymetric-candidates-v1", "run_metadata": {...}, "candidates": [ ... ] }<br>
<br>
# Sage output<br>
candidates = [ { ... }, { ... } ]<br>
<br>
# Mathematica output<br>
candidates = {<| "rank" -> 1, "h11" -> 12, ... |>, ...};</code>
            </div>

            <h3>Local Export Scripts</h3>
            <p>Use the adapter script to convert a saved results JSON file into tool-specific formats.</p>
            <div class="code-block">
                <code>python scripts/export_adapters.py --input static/data/results_RUN_ID.json --format cytools --output cytools.json<br>
python scripts/export_adapters.py --input static/data/results_RUN_ID.json --format cymetric --output cymetric.json<br>
python scripts/export_adapters.py --input static/data/results_RUN_ID.json --format sage --output candidates.sage<br>
python scripts/export_adapters.py --input static/data/results_RUN_ID.json --format mathematica --output candidates.wl</code>
            </div>

            <h3>Bring Your Own Data</h3>
            <p>Paste custom candidates as CSV rows in the Run page. Each row must include all feature columns for the selected dataset in order:</p>
            <ul>
                <li>Kreuzer-Skarke: h11, h21, euler_abs, hodge_ratio, c2_h11</li>
                <li>CY5-Folds: h11, h21, h31, euler, euler_abs, hodge_sum</li>
                <li>Heterotic: h11, h21, euler, euler_abs, hodge_ratio, hodge_balance, n_gen</li>
            </ul>

            <h3>Command-Line Options</h3>
            <div class="code-block">
                <code>--config CONFIG_FILE    Path to configuration YAML (default: default.yml)<br>
--verify                Verify top results against ground truth<br>
--export-artifacts      Generate CSV/JSON output files<br>
--top-k K              Number of top results to export (default: 100)<br>
--seed SEED            Random seed for reproducibility (default: 42)</code>
            </div>
        </section>

        <section class="section">
            <h2>Reproducibility Guarantees</h2>

            <h3>Fixed Random Seeds</h3>
            <p>All stochastic operations (model training, data shuffling) use deterministic seeds specified in the configuration file. Default seed is 42.</p>

            <h3>Pinned Dependencies</h3>
            <p>The <code>requirements.txt</code> file pins exact versions of all Python packages to ensure identical runtime environments.</p>
            <div class="code-block">
                <code>pip freeze > requirements.lock  # Generate locked dependencies</code>
            </div>

            <h3>Dataset Checksum Verification</h3>
            <p>Dataset downloads are verified using SHA-256 checksums before processing begins. If the checksum fails, the pipeline halts with an error.</p>
            <div class="code-block">
                <code># Expected checksum stored in config<br>
dataset_checksum: "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"</code>
            </div>

            <h3>Run Metadata</h3>
            <p>Every run generates a <code>repro.md</code> file containing:</p>
            <ul>
                <li>Timestamp and hostname</li>
                <li>Git commit hash</li>
                <li>Python version and environment info</li>
                <li>Configuration parameters used</li>
                <li>Dataset checksum verified</li>
                <li>Random seeds employed</li>
            </ul>
        </section>

        <section class="section">
            <h2>Configuration</h2>
            <p>Edit <code>default.yml</code> to customize pipeline behavior:</p>
            <div class="code-block">
                <code>dataset:<br>
  url: "https://example.com/cy_dataset.csv"<br>
  checksum: "sha256:e3b0c44..."<br>
<br>
model:<br>
  type: "random_forest"<br>
  n_estimators: 100<br>
  max_depth: 10<br>
<br>
search:<br>
  top_k: 100<br>
  verification: true<br>
  seed: 42</code>
            </div>
        </section>
    </main>
{% endblock %}
